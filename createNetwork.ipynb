{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is Thu Nov 29, 2018 14:02:16 for Last Run\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import networkx as nx\n",
    "import networkx.algorithms as algos\n",
    "from networkx.algorithms import approximation\n",
    "from networkTrips import organizeTrips\n",
    "from networkAlgos import networkAlgos\n",
    "from timeUtils import clock, elapsed, getDateTime\n",
    "from collections import Counter\n",
    "from haversine import haversine\n",
    "from ioUtils import loadJoblib\n",
    "from pandasUtils import getRowData, getColData, dropColumns\n",
    "from networkAlgos import networkAlgos\n",
    "from edgeInfo import edgeInfo\n",
    "from vertexInfo import vertexInfo\n",
    "from networkCategories import categories\n",
    "from place import getPlaceData\n",
    "from cbsa import getCBSAData\n",
    "from csa import getCSAData\n",
    "from metdiv import getMetDivData\n",
    "from county import getCountyData\n",
    "from state import getStateData\n",
    "from geocluster import geoClusters\n",
    "from geoUtils import convertMetersToLat, convertLatToMeters, convertMetersToLong, convertLongToMeters\n",
    "from geoclusterUtils import genCenters, genCluster, genClusters, genTripsBetweenClusters\n",
    "\n",
    "_, _ = clock(\"Last Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/tgadf/Downloads/gpsTripsOakRidge.p\n",
      "Current Time is Thu Nov 29, 2018 14:02:22 for Last Run\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# Generate Clusted Data\n",
    "#######################################################################################\n",
    "genData = False\n",
    "if genData:\n",
    "    cls     = 20\n",
    "    total   = 500\n",
    "    genMax  = 75\n",
    "    distMax = 500\n",
    "    raw  = genClusters(cls, 250, latRange=[29.8, 30.2], lngRange=[49.8, 50.2], dist=\"gauss\", maxrad=genMax)\n",
    "    gc   = geoClusters(key=\"dummy\", points=raw, distMax=distMax, debug=False)\n",
    "    gc.findClusters(seedMin=2, debug=False)\n",
    "    df   = genTripsBetweenClusters(n=total, gc=gc, returnDF=True)\n",
    "    df[\"device\"] = \"dummy\"    \n",
    "    \n",
    "    tmpdf = loadJoblib(\"/Users/tgadfort/Downloads/r4hIDs.p\").sample(n=total, replace=True)\n",
    "    tojoin = tmpdf.sample(cls)\n",
    "    tojoin[\"cl\"] = [\"cl{0}\".format(x) for x in range(cls)]\n",
    "\n",
    "    df['cl'] = df['cl0']\n",
    "    drops = [x for x in tojoin.columns if x.startswith(\"Geo1\")]\n",
    "    tojoinCL0 = dropColumns(tojoin, columns=drops, inplace=False)\n",
    "    test = df.merge(tojoinCL0, on='cl')\n",
    "\n",
    "    test['cl'] = test['cl1']\n",
    "    drops = [x for x in tojoin.columns if x.startswith(\"Geo0\")]\n",
    "    tojoinCL1 = dropColumns(tojoin, columns=drops, inplace=False)\n",
    "    test = test.merge(tojoinCL1, on='cl')\n",
    "\n",
    "    gpsdata = test\n",
    "    dropColumns(gpsdata, columns=[\"cl\", \"cl0\", \"cl1\"])\n",
    "    gpsdata.replace('nan', 0, inplace=True)\n",
    "else:\n",
    "    fname = \"/Users/tgadf/Downloads/gpsTripsOakRidge.p\"\n",
    "    print(\"Loading {0}\".format(fname))\n",
    "    gpsdata = loadJoblib(fname)    \n",
    "\n",
    "_, _ = clock(\"Last Run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>total_miles</th>\n",
       "      <th>heading0</th>\n",
       "      <th>lat0</th>\n",
       "      <th>long0</th>\n",
       "      <th>heading1</th>\n",
       "      <th>lat1</th>\n",
       "      <th>long1</th>\n",
       "      <th>...</th>\n",
       "      <th>Geo0CENSUSCousub</th>\n",
       "      <th>Geo1CENSUSCousub</th>\n",
       "      <th>Geo0CENSUSPlace</th>\n",
       "      <th>Geo1CENSUSPlace</th>\n",
       "      <th>Geo0CENSUSMetdiv</th>\n",
       "      <th>Geo1CENSUSMetdiv</th>\n",
       "      <th>Geo0CENSUSCsa</th>\n",
       "      <th>Geo1CENSUSCsa</th>\n",
       "      <th>Geo0CENSUSCbsa</th>\n",
       "      <th>Geo1CENSUSCbsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353162075845793</td>\n",
       "      <td>2018-01-05 16:34:48</td>\n",
       "      <td>2018-01-05 16:52:44</td>\n",
       "      <td>4.5</td>\n",
       "      <td>210</td>\n",
       "      <td>29.305593</td>\n",
       "      <td>-94.814782</td>\n",
       "      <td>240</td>\n",
       "      <td>29.270787</td>\n",
       "      <td>-94.828297</td>\n",
       "      <td>...</td>\n",
       "      <td>4816791445</td>\n",
       "      <td>4816791445</td>\n",
       "      <td>4828068</td>\n",
       "      <td>4828068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "      <td>26420</td>\n",
       "      <td>26420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352252066676025</td>\n",
       "      <td>2018-04-11 12:03:33</td>\n",
       "      <td>2018-04-11 12:38:29</td>\n",
       "      <td>28.2</td>\n",
       "      <td>258</td>\n",
       "      <td>39.556667</td>\n",
       "      <td>-94.328497</td>\n",
       "      <td>276</td>\n",
       "      <td>39.243590</td>\n",
       "      <td>-94.450912</td>\n",
       "      <td>...</td>\n",
       "      <td>2904940844</td>\n",
       "      <td>2904742050</td>\n",
       "      <td>2940826</td>\n",
       "      <td>2938000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>28140</td>\n",
       "      <td>28140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352252069073014</td>\n",
       "      <td>2018-10-19 18:36:45</td>\n",
       "      <td>2018-10-19 18:44:17</td>\n",
       "      <td>1.5</td>\n",
       "      <td>96</td>\n",
       "      <td>27.638193</td>\n",
       "      <td>-80.438187</td>\n",
       "      <td>258</td>\n",
       "      <td>27.640823</td>\n",
       "      <td>-80.453530</td>\n",
       "      <td>...</td>\n",
       "      <td>1206193510</td>\n",
       "      <td>1206193510</td>\n",
       "      <td>1274150</td>\n",
       "      <td>1276937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>42680</td>\n",
       "      <td>42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352252069073014</td>\n",
       "      <td>2018-10-26 18:35:46</td>\n",
       "      <td>2018-10-26 18:46:45</td>\n",
       "      <td>3.6</td>\n",
       "      <td>330</td>\n",
       "      <td>27.638383</td>\n",
       "      <td>-80.399235</td>\n",
       "      <td>276</td>\n",
       "      <td>27.640792</td>\n",
       "      <td>-80.453505</td>\n",
       "      <td>...</td>\n",
       "      <td>1206193510</td>\n",
       "      <td>1206193510</td>\n",
       "      <td>1274150</td>\n",
       "      <td>1276937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>42680</td>\n",
       "      <td>42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352252068844514</td>\n",
       "      <td>2017-04-13 20:10:24</td>\n",
       "      <td>2017-04-13 20:27:32</td>\n",
       "      <td>8.4</td>\n",
       "      <td>156</td>\n",
       "      <td>30.334510</td>\n",
       "      <td>-87.137922</td>\n",
       "      <td>252</td>\n",
       "      <td>30.387688</td>\n",
       "      <td>-87.064705</td>\n",
       "      <td>...</td>\n",
       "      <td>1203392691</td>\n",
       "      <td>1211392218</td>\n",
       "      <td>0</td>\n",
       "      <td>1271842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37860</td>\n",
       "      <td>37860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            device                Start                  End  total_miles  \\\n",
       "0  353162075845793  2018-01-05 16:34:48  2018-01-05 16:52:44          4.5   \n",
       "1  352252066676025  2018-04-11 12:03:33  2018-04-11 12:38:29         28.2   \n",
       "2  352252069073014  2018-10-19 18:36:45  2018-10-19 18:44:17          1.5   \n",
       "3  352252069073014  2018-10-26 18:35:46  2018-10-26 18:46:45          3.6   \n",
       "4  352252068844514  2017-04-13 20:10:24  2017-04-13 20:27:32          8.4   \n",
       "\n",
       "  heading0       lat0      long0 heading1       lat1      long1  \\\n",
       "0      210  29.305593 -94.814782      240  29.270787 -94.828297   \n",
       "1      258  39.556667 -94.328497      276  39.243590 -94.450912   \n",
       "2       96  27.638193 -80.438187      258  27.640823 -80.453530   \n",
       "3      330  27.638383 -80.399235      276  27.640792 -80.453505   \n",
       "4      156  30.334510 -87.137922      252  30.387688 -87.064705   \n",
       "\n",
       "        ...        Geo0CENSUSCousub  Geo1CENSUSCousub  Geo0CENSUSPlace  \\\n",
       "0       ...              4816791445        4816791445          4828068   \n",
       "1       ...              2904940844        2904742050          2940826   \n",
       "2       ...              1206193510        1206193510          1274150   \n",
       "3       ...              1206193510        1206193510          1274150   \n",
       "4       ...              1203392691        1211392218                0   \n",
       "\n",
       "   Geo1CENSUSPlace  Geo0CENSUSMetdiv  Geo1CENSUSMetdiv  Geo0CENSUSCsa  \\\n",
       "0          4828068                 0                 0            288   \n",
       "1          2938000                 0                 0            312   \n",
       "2          1276937                 0                 0            442   \n",
       "3          1276937                 0                 0            442   \n",
       "4          1271842                 0                 0              0   \n",
       "\n",
       "   Geo1CENSUSCsa  Geo0CENSUSCbsa  Geo1CENSUSCbsa  \n",
       "0            288           26420           26420  \n",
       "1            312           28140           28140  \n",
       "2            442           42680           42680  \n",
       "3            442           42680           42680  \n",
       "4              0           37860           37860  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpsdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subselect (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 3066 rows\n"
     ]
    }
   ],
   "source": [
    "device  = '352252060173789'\n",
    "gpsdata = gpsdata[gpsdata['device'] == device]\n",
    "print(\"Keeping {0} rows\".format(gpsdata.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Cluster and Sort Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key = 352252060173789 \tRun = 0/1 \tTrips = 3066\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Converting 6132 Points To Correct Format\n",
      "Data has correct format with a (6132, 2) shape.\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Done with Converting 6132 Points To Correct Format\n",
      "Process [Done with Converting 6132 Points To Correct Format] took 0 seconds.\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Finding Geohash (BitLen=8) Values from 6132 Points\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Done with Finding Geohash (BitLen=8) Values from 6132 Points\n",
      "Process [Done with Finding Geohash (BitLen=8) Values from 6132 Points] took 0 seconds.\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Finding Geohash (BitLen=8) Frequency Values from Geohash DataFrame\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Done with Finding Geohash (BitLen=8) Frequency Values from Geohash DataFrame\n",
      "Process [Done with Finding Geohash (BitLen=8) Frequency Values from Geohash DataFrame] took 0 seconds.\n",
      "Current Time is Thu Nov 29, 2018 14:02:23 for Finding Clusters with at least 4 counts\n",
      "  --> Creating cluster cl0 with seed dnk50xx1 and 1354 counts\n",
      "  --> Creating cluster cl1 with seed dnk52cux and 176 counts\n",
      "  --> Creating cluster cl2 with seed dnkhhp7z and 94 counts\n",
      "  --> Creating cluster cl3 with seed dnk5dw1k and 75 counts\n",
      "  --> Creating cluster cl4 with seed dnkhexwt and 56 counts\n",
      "  --> Creating cluster cl5 with seed dnk5d7rk and 56 counts\n",
      "  --> Creating cluster cl6 with seed dnk5cscf and 52 counts\n",
      "  --> Creating cluster cl7 with seed dnk50nm3 and 52 counts\n",
      "  --> Creating cluster cl8 with seed dnkhgjx1 and 34 counts\n",
      "  --> Creating cluster cl9 with seed dnk5f1zj and 31 counts\n",
      "  --> Creating cluster cl10 with seed dnkq4j2y and 30 counts\n",
      "  --> Creating cluster cl11 with seed dnkhy0vy and 29 counts\n",
      "  --> Creating cluster cl12 with seed dnkh59p8 and 28 counts\n",
      "  --> Creating cluster cl13 with seed dnkhm0j2 and 27 counts\n",
      "  --> Creating cluster cl14 with seed dnk52fed and 25 counts\n",
      "  --> Creating cluster cl15 with seed dnk5cgsw and 24 counts\n",
      "  --> Creating cluster cl16 with seed dnk529zk and 22 counts\n",
      "  --> Creating cluster cl17 with seed dnkhjqgj and 18 counts\n",
      "  --> Creating cluster cl18 with seed dnkhgmc8 and 18 counts\n",
      "  --> Creating cluster cl19 with seed dnkhfhhn and 17 counts\n",
      "  --> Creating cluster cl20 with seed dnkhmt6w and 17 counts\n",
      "  --> Creating cluster cl21 with seed dnkhhwc4 and 16 counts\n",
      "  --> Creating cluster cl22 with seed dnk5f2y3 and 14 counts\n",
      "  --> Creating cluster cl23 with seed dnkhsr0p and 14 counts\n",
      "  --> Creating cluster cl24 with seed dnk50wxu and 14 counts\n",
      "  --> Creating cluster cl25 with seed dnkhxjcm and 13 counts\n",
      "  --> Creating cluster cl26 with seed dnk5dteu and 13 counts\n",
      "  --> Creating cluster cl27 with seed dnkhff7q and 13 counts\n",
      "  --> Creating cluster cl28 with seed dnk5dx0c and 13 counts\n",
      "  --> Creating cluster cl29 with seed dnk5g5sc and 12 counts\n",
      "  --> Creating cluster cl30 with seed dn7s1zee and 12 counts\n",
      "  --> Creating cluster cl31 with seed dnk5f4fx and 12 counts\n",
      "  --> Creating cluster cl32 with seed dnkhfq2n and 11 counts\n",
      "  --> Creating cluster cl33 with seed dnk50q8j and 10 counts\n",
      "  --> Creating cluster cl34 with seed dnkhhw7h and 10 counts\n",
      "  --> Creating cluster cl35 with seed dnkhjz6p and 10 counts\n",
      "  --> Creating cluster cl36 with seed dnk5drxz and 10 counts\n",
      "  --> Creating cluster cl37 with seed dnkhjpdc and 10 counts\n",
      "  --> Creating cluster cl38 with seed dnk50rxy and 8 counts\n",
      "  --> Creating cluster cl39 with seed dn7fmxc8 and 8 counts\n",
      "  --> Creating cluster cl40 with seed dnk50mf5 and 8 counts\n",
      "  --> Creating cluster cl41 with seed dn7gqg3k and 8 counts\n",
      "  --> Creating cluster cl42 with seed dr0rszqz and 8 counts\n",
      "  --> Creating cluster cl43 with seed dn7ftcnb and 7 counts\n",
      "  --> Creating cluster cl44 with seed dn7grbxk and 7 counts\n",
      "  --> Creating cluster cl45 with seed dnkhfspp and 7 counts\n",
      "  --> Creating cluster cl46 with seed dnkhfg0c and 6 counts\n",
      "  --> Creating cluster cl47 with seed dn7s1xn9 and 6 counts\n",
      "  --> Creating cluster cl48 with seed dnk53jnq and 6 counts\n",
      "  --> Creating cluster cl49 with seed dnk5dsyq and 6 counts\n",
      "  --> Creating cluster cl50 with seed dnkhnwvk and 6 counts\n",
      "  --> Creating cluster cl51 with seed dnkhgm7d and 6 counts\n",
      "  --> Creating cluster cl52 with seed dnk5f3cw and 6 counts\n",
      "  --> Creating cluster cl53 with seed dnkhmjju and 5 counts\n",
      "  --> Creating cluster cl54 with seed dn7s8fv7 and 5 counts\n",
      "  --> Creating cluster cl55 with seed dnkhgkct and 5 counts\n",
      "  --> Creating cluster cl56 with seed dn7s1z35 and 5 counts\n",
      "  --> Creating cluster cl57 with seed dn7gr8ug and 5 counts\n",
      "  --> Creating cluster cl58 with seed dn7ftbsx and 4 counts\n",
      "  --> Creating cluster cl59 with seed dnkhr5z0 and 4 counts\n",
      "  --> Creating cluster cl60 with seed dnkhzgpc and 4 counts\n",
      "  --> Creating cluster cl61 with seed dnkqjpxh and 4 counts\n",
      "  --> Creating cluster cl62 with seed dnkhwz9z and 4 counts\n",
      "  --> Creating cluster cl63 with seed dn7s90sr and 4 counts\n",
      "  --> Creating cluster cl64 with seed dn2yc8sr and 4 counts\n",
      "  --> Creating cluster cl65 with seed dnkhsqdy and 4 counts\n",
      "  --> Creating cluster cl66 with seed dnkhhzk1 and 4 counts\n",
      "  --> Creating cluster cl67 with seed dr0q9nq9 and 4 counts\n",
      "  --> Creating cluster cl68 with seed dnk52842 and 4 counts\n",
      "  --> Creating cluster cl69 with seed dnkh588h and 4 counts\n",
      "  --> Creating cluster cl70 with seed dnkhjh7j and 4 counts\n",
      "  --> Creating cluster cl71 with seed dnkhhg27 and 4 counts\n",
      "  --> Creating cluster cl72 with seed dn7fqv1x and 4 counts\n",
      "  --> Creating cluster cl73 with seed dn2ycb1g and 4 counts\n",
      "  --> Creating cluster cl74 with seed dnk5f81k and 4 counts\n",
      "  --> Creating cluster cl75 with seed dnkkd7cg and 4 counts\n",
      "  --> Creating cluster cl76 with seed dnkhq0de and 4 counts\n",
      "  --> Creating cluster cl77 with seed dnk528gd and 4 counts\n",
      "  --> Creating cluster cl78 with seed dn7grb98 and 4 counts\n",
      "  --> Creating cluster cl79 with seed dnkhjjm3 and 4 counts\n",
      "  --> Creating cluster cl80 with seed dnt87k94 and 4 counts\n",
      "  --> Creating cluster cl81 with seed dn7fw0t0 and 4 counts\n",
      "  --> Creating cluster cl82 with seed dnkhhz3m and 4 counts\n",
      "  --> Creating cluster cl83 with seed dnk53rvv and 4 counts\n",
      "  --> Creating cluster cl84 with seed dnk5d4j2 and 4 counts\n",
      "  --> Creating cluster cl85 with seed dnk4cw97 and 4 counts\n",
      "  --> Creating cluster cl86 with seed dnk1bjrj and 4 counts\n",
      "Current Time is Thu Nov 29, 2018 14:02:24 for Done with Finding Clusters with at least 4 counts\n",
      "Process [Done with Finding Clusters with at least 4 counts] took 1 seconds.\n",
      "Found 87 clusters using 581 cells and 5509 counts\n",
      "Current Time is Thu Nov 29, 2018 14:02:24 for Finding Nearest Clusters for Start of Trips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/census/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is Thu Nov 29, 2018 14:02:27 for Done with Finding Nearest Clusters for Start of Trips\n",
      "Process [Done with Finding Nearest Clusters for Start of Trips] took 2 seconds.\n",
      "Current Time is Thu Nov 29, 2018 14:02:27 for Finding Nearest Clusters for End of Trips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/census/lib/python3.6/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tgadf/Documents/code/network/networkTimeUtils.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trips['start'] = castDateTime(trips['Start'])\n",
      "/Users/tgadf/Documents/code/network/networkTimeUtils.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trips['end']   = castDateTime(trips['End'])\n",
      "/Users/tgadf/Documents/code/network/networkTimeUtils.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trips['date']  = convertToDate(trips['start'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is Thu Nov 29, 2018 14:02:30 for Done with Finding Nearest Clusters for End of Trips\n",
      "Process [Done with Finding Nearest Clusters for End of Trips] took 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "i  = 0\n",
    "nd = gpsdata['device'].nunique() \n",
    "for device, df in gpsdata.groupby('device'):\n",
    "    print('Key = {0}'.format(device),'\\tRun = {0}/{1}'.format(i,nd),'\\tTrips = {0}'.format(df.shape[0]))\n",
    "    i += 1\n",
    "\n",
    "    #######################################################################################\n",
    "    # Cluster Geo Data (Lat, Long)\n",
    "    #######################################################################################\n",
    "    points         = df[[\"lat0\", \"long0\"]]\n",
    "    points.columns = [\"lat\", \"long\"]\n",
    "    pnts           = df[[\"lat1\", \"long1\"]]\n",
    "    pnts.columns   = [\"lat\", \"long\"]    \n",
    "    points         = points.append(pnts)\n",
    "\n",
    "\n",
    "\n",
    "    #######################################################################################\n",
    "    # Create Clusters\n",
    "    #######################################################################################\n",
    "    debug=True\n",
    "    gc   = geoClusters(key=\"dummy\", points=points, distMax=300, debug=debug)\n",
    "    gc.findClusters(seedMin=4, debug=debug)\n",
    "    if debug:\n",
    "        print(\"Found {0} clusters using {1} cells and {2} counts\".format(gc.getNClusters(), gc.getNCells(), gc.getNCounts()))\n",
    "\n",
    "\n",
    "\n",
    "    #######################################################################################\n",
    "    # Set Nearest Clusters\n",
    "    #######################################################################################\n",
    "    if debug:\n",
    "        start, cmt = clock(\"Finding Nearest Clusters for Start of Trips\")\n",
    "    geoResults = df[['lat0', 'long0']].apply(gc.getNearestClusters, axis=1).values\n",
    "    df[\"geo0\"] = [x[0] for x in geoResults]\n",
    "    if debug:\n",
    "        elapsed(start, cmt)\n",
    "        start, cmt = clock(\"Finding Nearest Clusters for End of Trips\")\n",
    "    geoResults = df[['lat1', 'long1']].apply(gc.getNearestClusters, axis=1).values\n",
    "    df[\"geo1\"] = [x[0] for x in geoResults]    \n",
    "    if debug:\n",
    "        elapsed(start, cmt)\n",
    "\n",
    "\n",
    "\n",
    "    #######################################################################################\n",
    "    # Organize Trips for Network\n",
    "    #######################################################################################\n",
    "    trips = organizeTrips(df=df, gc=gc, debug=False, requireGood=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>total_miles</th>\n",
       "      <th>heading0</th>\n",
       "      <th>lat0</th>\n",
       "      <th>long0</th>\n",
       "      <th>heading1</th>\n",
       "      <th>lat1</th>\n",
       "      <th>long1</th>\n",
       "      <th>...</th>\n",
       "      <th>Geo1CENSUSMetdiv</th>\n",
       "      <th>Geo0CENSUSCsa</th>\n",
       "      <th>Geo1CENSUSCsa</th>\n",
       "      <th>Geo0CENSUSCbsa</th>\n",
       "      <th>Geo1CENSUSCbsa</th>\n",
       "      <th>geo0</th>\n",
       "      <th>geo1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>352252060173789</td>\n",
       "      <td>2018-02-01 15:56:11</td>\n",
       "      <td>2018-02-01 17:08:03</td>\n",
       "      <td>1.5</td>\n",
       "      <td>60</td>\n",
       "      <td>35.894323</td>\n",
       "      <td>-84.172757</td>\n",
       "      <td>66</td>\n",
       "      <td>35.900737</td>\n",
       "      <td>-84.151165</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>28940</td>\n",
       "      <td>28940</td>\n",
       "      <td>cl34</td>\n",
       "      <td>cl37</td>\n",
       "      <td>2018-02-01 15:56:11</td>\n",
       "      <td>2018-02-01 17:08:03</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>352252060173789</td>\n",
       "      <td>2018-03-17 20:06:12</td>\n",
       "      <td>2018-03-17 20:08:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>66</td>\n",
       "      <td>35.900952</td>\n",
       "      <td>-84.149263</td>\n",
       "      <td>72</td>\n",
       "      <td>35.900740</td>\n",
       "      <td>-84.151158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>28940</td>\n",
       "      <td>28940</td>\n",
       "      <td>cl37</td>\n",
       "      <td>cl37</td>\n",
       "      <td>2018-03-17 20:06:12</td>\n",
       "      <td>2018-03-17 20:08:00</td>\n",
       "      <td>2018-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>352252060173789</td>\n",
       "      <td>2017-11-01 11:26:21</td>\n",
       "      <td>2017-11-01 11:32:45</td>\n",
       "      <td>1.8</td>\n",
       "      <td>348</td>\n",
       "      <td>35.719990</td>\n",
       "      <td>-84.342105</td>\n",
       "      <td>138</td>\n",
       "      <td>35.718357</td>\n",
       "      <td>-84.367467</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>28940</td>\n",
       "      <td>28940</td>\n",
       "      <td>cl24</td>\n",
       "      <td>cl7</td>\n",
       "      <td>2017-11-01 11:26:21</td>\n",
       "      <td>2017-11-01 11:32:45</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>352252060173789</td>\n",
       "      <td>2017-09-08 15:12:41</td>\n",
       "      <td>2017-09-08 15:43:06</td>\n",
       "      <td>10.3</td>\n",
       "      <td>48</td>\n",
       "      <td>35.782707</td>\n",
       "      <td>-84.279475</td>\n",
       "      <td>252</td>\n",
       "      <td>35.718437</td>\n",
       "      <td>-84.367578</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>28940</td>\n",
       "      <td>28940</td>\n",
       "      <td>cl84</td>\n",
       "      <td>cl7</td>\n",
       "      <td>2017-09-08 15:12:41</td>\n",
       "      <td>2017-09-08 15:43:06</td>\n",
       "      <td>2017-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>352252060173789</td>\n",
       "      <td>2018-05-09 13:22:14</td>\n",
       "      <td>2018-05-09 13:46:36</td>\n",
       "      <td>4.3</td>\n",
       "      <td>288</td>\n",
       "      <td>35.725037</td>\n",
       "      <td>-84.343327</td>\n",
       "      <td>72</td>\n",
       "      <td>35.718428</td>\n",
       "      <td>-84.367603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>28940</td>\n",
       "      <td>28940</td>\n",
       "      <td>cl0</td>\n",
       "      <td>cl7</td>\n",
       "      <td>2018-05-09 13:22:14</td>\n",
       "      <td>2018-05-09 13:46:36</td>\n",
       "      <td>2018-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               device                Start                  End  total_miles  \\\n",
       "946   352252060173789  2018-02-01 15:56:11  2018-02-01 17:08:03          1.5   \n",
       "953   352252060173789  2018-03-17 20:06:12  2018-03-17 20:08:00          0.1   \n",
       "4374  352252060173789  2017-11-01 11:26:21  2017-11-01 11:32:45          1.8   \n",
       "4376  352252060173789  2017-09-08 15:12:41  2017-09-08 15:43:06         10.3   \n",
       "4378  352252060173789  2018-05-09 13:22:14  2018-05-09 13:46:36          4.3   \n",
       "\n",
       "     heading0       lat0      long0 heading1       lat1      long1  \\\n",
       "946        60  35.894323 -84.172757       66  35.900737 -84.151165   \n",
       "953        66  35.900952 -84.149263       72  35.900740 -84.151158   \n",
       "4374      348  35.719990 -84.342105      138  35.718357 -84.367467   \n",
       "4376       48  35.782707 -84.279475      252  35.718437 -84.367578   \n",
       "4378      288  35.725037 -84.343327       72  35.718428 -84.367603   \n",
       "\n",
       "         ...      Geo1CENSUSMetdiv  Geo0CENSUSCsa  Geo1CENSUSCsa  \\\n",
       "946      ...                     0            314            314   \n",
       "953      ...                     0            314            314   \n",
       "4374     ...                     0            314            314   \n",
       "4376     ...                     0            314            314   \n",
       "4378     ...                     0            314            314   \n",
       "\n",
       "      Geo0CENSUSCbsa  Geo1CENSUSCbsa  geo0  geo1               start  \\\n",
       "946            28940           28940  cl34  cl37 2018-02-01 15:56:11   \n",
       "953            28940           28940  cl37  cl37 2018-03-17 20:06:12   \n",
       "4374           28940           28940  cl24   cl7 2017-11-01 11:26:21   \n",
       "4376           28940           28940  cl84   cl7 2017-09-08 15:12:41   \n",
       "4378           28940           28940   cl0   cl7 2018-05-09 13:22:14   \n",
       "\n",
       "                     end        date  \n",
       "946  2018-02-01 17:08:03  2018-02-01  \n",
       "953  2018-03-17 20:08:00  2018-03-17  \n",
       "4374 2017-11-01 11:32:45  2017-11-01  \n",
       "4376 2017-09-08 15:43:06  2017-09-08  \n",
       "4378 2018-05-09 13:46:36  2018-05-09  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data if needed\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    def __init__(self, directed=True, debug=False):\n",
    "        self.debug = debug\n",
    "        self.directed = directed\n",
    "        \n",
    "        self.orderedEdges    = None\n",
    "        self.edgeDict        = None\n",
    "        self.orderedVertices = None\n",
    "        self.nodeDict        = None\n",
    "        \n",
    "        if self.directed is True:\n",
    "            self.g = nx.DiGraph()\n",
    "        else:\n",
    "            self.g = nx.Graph()\n",
    "\n",
    "        self.eInfo            = edgeInfo(self.g, self.debug)\n",
    "        self.getEdges         = self.eInfo.getEdges\n",
    "        self.getEdge          = self.eInfo.getEdgeData\n",
    "        self.getEdgeAttrs     = self.eInfo.getAttrGroups\n",
    "        self.setEdgeFeature   = self.eInfo.setEdgeFeature        \n",
    "        self.getEdgeNum       = self.eInfo.getEdgeNumByName\n",
    "        \n",
    "        self.vInfo            = vertexInfo(self.g, self.debug)\n",
    "        self.getVertices      = self.vInfo.getVertices\n",
    "        self.getVertex        = self.vInfo.getVertexData\n",
    "        self.getVertexByName  = self.vInfo.getVertexDataByName\n",
    "        self.getVertexAttrs   = self.vInfo.getAttrGroups\n",
    "        self.setVertexFeature = self.vInfo.setVertexFeature        \n",
    "        self.getVertexNum     = self.vInfo.getVertexNumByName\n",
    "            \n",
    "    def setDebug(self, debug):\n",
    "        self.debug = debug\n",
    "        \n",
    "    def getNetwork(self):\n",
    "        return self.g\n",
    "    \n",
    "    \n",
    "    def update(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Updating Vertices/Edges\")\n",
    "        self.eInfo.orderEdges(debug=debug)\n",
    "        self.vInfo.orderVertices(debug=debug)\n",
    "        \n",
    "            \n",
    "    def flattenAttrs(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Flattening Vertices/Edges\")\n",
    "        self.eInfo.flattenEdgeAttrs(debug=debug)\n",
    "        self.vInfo.flattenVertexAttrs(debug=debug)\n",
    "        \n",
    "    \n",
    "    def collectAttrs(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Collecting Vertices/Edges\")\n",
    "        self.eInfo.collectEdgeAttrs(debug=debug)\n",
    "        self.vInfo.collectVertexAttrs(debug=debug)\n",
    "    \n",
    "    \n",
    "    ################################################################################################\n",
    "    # Show Network Data\n",
    "    ################################################################################################    \n",
    "    def showVertices(self):\n",
    "        for nodename,node in self.g.nodes_iter(data=True):\n",
    "            print(nodename,'\\t',node)\n",
    "                \n",
    "    def showEdges(self):\n",
    "        for edgename,edge in self.g.adj.items():\n",
    "            print(edgename,'\\t',edge)\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "    ################################################################################################\n",
    "    # Vertices / Nodes / Location (Initial Functions)\n",
    "    ################################################################################################    \n",
    "    def addVertex(self, name, attrs={}):\n",
    "        self.g.add_node(u=name, attr_dict=attrs)\n",
    "        if self.debug:\n",
    "            print(\"  Added node: [{0}]\".format(\", \".join(names)))\n",
    "                    \n",
    "    def updateVertexAttrs(self, attrs, debug=False):\n",
    "        if debug:\n",
    "            print(\"Updating Vertex Attributes\")\n",
    "        if not isinstance(attrs, dict):\n",
    "            print(\"Cannot add vertex attrs because the input is not a dict\")\n",
    "            return\n",
    "        nx.set_node_attributes(G=self.g, values=attrs, name=None)\n",
    "            \n",
    "        \n",
    "        \n",
    "    ################################################################################################\n",
    "    # Edges / Trips (Initial Functions)\n",
    "    ################################################################################################    \n",
    "    def addEdge(self, names, attrs={}, sort=False):\n",
    "        if not isinstance(names, (tuple,list,set)):\n",
    "            print(\"Cannot add edge {0} because the names need to come in a tuple/list/set.\".format(names))\n",
    "            return\n",
    "        if len(names) == 2:\n",
    "            if sort is True:\n",
    "                names = sorted([str(x) for x in names])\n",
    "            else:\n",
    "                names = [str(x) for x in names]\n",
    "        else:\n",
    "            print(\"Cannot add edge {0} because we need two entries in the tuple/list/set.\".format(names))\n",
    "            return\n",
    "        \n",
    "        self.g.add_edge(names[0], names[1], attr_dict=attrs)\n",
    "        if self.debug:\n",
    "            print(\"  Added edge: [{0}]\".format(\", \".join(names)))\n",
    "            \n",
    "    def updateEdgeAttrs(self, attrs):\n",
    "        if not isinstance(attrs, dict):\n",
    "            print(\"Cannot add edge attrs because the input is not a dict\")\n",
    "            return\n",
    "        nx.set_edge_attributes(G=self.g, values=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class driverNetwork(network):\n",
    "    def __init__(self, trips):\n",
    "        network.__init__(self, directed=False, debug=False)\n",
    "        \n",
    "        self.categories        = categories(debug)\n",
    "        self.getCategories     = self.categories.getCategories\n",
    "        self.getCategory       = self.categories.getCategory\n",
    "        self.getPermCategories = self.categories.getPermCategories\n",
    "        self.getPermCategory   = self.categories.getPermCategory  \n",
    "        self.getHomeRatioCategory = self.categories.getHomeRatioCategory\n",
    "        self.getIntervalCategory = self.categories.getIntervalCategory\n",
    "        \n",
    "        \n",
    "        if trips is not None:\n",
    "            if isinstance(trips, dict):\n",
    "                self.name          = trips.get('device')\n",
    "                self.edgeMetrics   = trips.get('edgeMetrics')\n",
    "                self.vertexMetrics = trips.get('vertexMetrics')\n",
    "                self.vertexMetrics = {str(k): v for k,v in self.vertexMetrics.items()}\n",
    "                self.homeMetrics   = trips.get('homeMetrics')\n",
    "                print(\"Creating a driver network with {0} vertices and {1} edges.\".format(len(self.vertexMetrics), len(self.edgeMetrics)))\n",
    "            else:\n",
    "                raise ValueError(\"Input trips must be a dictionary of edgeMetrics, vertexMetrics, and homeMetrics (optional)\")\n",
    "        else:\n",
    "            raise ValueError(\"Input trips is None!\")\n",
    "\n",
    "            \n",
    "    ####################################################################################\n",
    "    # Create Network\n",
    "    ####################################################################################\n",
    "    def create(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Creating Network Attributes\")\n",
    "        for edgename,edgedata in self.edgeMetrics.items():\n",
    "            self.addEdge(edgename, edgedata)\n",
    "        self.updateVertexAttrs(self.vertexMetrics, debug=debug)\n",
    "        self.update(debug=debug)\n",
    "        self.flattenAttrs(debug=debug)\n",
    "        self.collectAttrs(debug=debug)\n",
    "\n",
    "        \n",
    "    ####################################################################################\n",
    "    # Compute Network Attributes\n",
    "    ####################################################################################\n",
    "    def computeNetworkAttrs(self, level=2, debug=False):\n",
    "        if debug:\n",
    "            if level == 1:\n",
    "                print(\"Computing Network Attributes (simple)\")\n",
    "            elif level == 2:\n",
    "                print(\"Computing Network Attributes (medium)\")\n",
    "            elif level == 3:\n",
    "                print(\"Computing Network Attributes (hard)\")\n",
    "        self.netAlgos = networkAlgos()\n",
    "        results = self.netAlgos.compute(self.g, level=level, debug=debug)\n",
    "        self.nodeAttrs = results['Nodes']\n",
    "        self.edgeAttrs = results['Edges']\n",
    "        self.edgeAttrs['edge_weight'] = self.eInfo.getEdgeWeights().values() # add weights\n",
    "        self.netAttrs  = results['Net']\n",
    "        if debug:\n",
    "            print(\"  Created {0} attributes for {1} vertices\".format(self.nodeAttrs.shape[1], self.nodeAttrs.shape[0]))\n",
    "            print(\"  Created {0} attributes for {1} edges\".format(self.edgeAttrs.shape[1], self.edgeAttrs.shape[0]))\n",
    "            print(\"  Created {0} attributes for the network\".format(len(self.netAttrs)))\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    # Perform Lookup for Census Data\n",
    "    ####################################################################################\n",
    "    def fillCensusData(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Vertex Census Data\")\n",
    "        verydebug=False\n",
    "\n",
    "        print(self.getVertexAttrs().keys())\n",
    "        1/0\n",
    "        \n",
    "        censusKeys = [k for k,v in self.getVertexAttrs().items() if v == \"Census\"]\n",
    "        getCensusData = {\"CensusCbsa\": getCBSAData, \"CensusCsa\": getCSAData, \"CensusCounty\": getCountyData, \"CensusMetdiv\": getMetDivData, \"CensusPlace\": getPlaceData, \"CensusState\": getStateData}\n",
    "        for key in censusKeys:\n",
    "            if getCensusData.get(key) is None:\n",
    "                continue\n",
    "            for vertexName in self.getVertices():\n",
    "                vertex = self.getVertexByName(vertexName, 'attr')\n",
    "                if verydebug:\n",
    "                    print(\"  --> Vertex Number {0} and ID {1}\".format(vertexNum, vertexID))\n",
    "\n",
    "                value   = vertex[key]\n",
    "                \n",
    "                \n",
    "                if isinstance(value, list):\n",
    "                    try:\n",
    "                        #mc    = value.most_common(1)\n",
    "                        value = value[0][0]\n",
    "                    except:\n",
    "                        print(\"There was an error getting most common {0}\".format(key))\n",
    "                        value = None        \n",
    "                else:\n",
    "                    print(\"Input {0} is type {1}\".format(value, type(value)))\n",
    "                    \n",
    "                try:\n",
    "                    lookup       = getCensusData[key](str(value))\n",
    "                    features     = self.categories.getFeatures(key, lookup, debug)\n",
    "                except:\n",
    "                    raise ValueError(\"Something went wrong with census lookup for {0} and value {1}\".format(key, value))\n",
    "\n",
    "                for lookupName,lookupValue in features.items():\n",
    "                    featureName = \"\".join([key,lookupName])\n",
    "                    self.setVertexFeature(vertexName, featureName, lookupValue)\n",
    "                \n",
    "                if verydebug is True:\n",
    "                    print(\"\\t: {0}, {1} == {2} ({3})\".format(key, value, lookup, features))\n",
    "                    \n",
    "        if verydebug:\n",
    "            raise ValueError(\"Stoppping after verydebug is True\")\n",
    "            \n",
    "\n",
    "    def fillGeospatialData(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Vertex Geospatial Data\")\n",
    "        verydebug=False\n",
    "\n",
    "        groupings = [\"HEREPOI\", \"OSM\", \"Road\", \"Terminal\"]\n",
    "        for grouping in groupings:\n",
    "            keys = [k for k,v in self.getVertexAttrs().items() if v == grouping]            \n",
    "            for vertexName in self.getVertices():\n",
    "                vertex = self.getVertexByName(vertexName, 'attr')\n",
    "                if verydebug:\n",
    "                    print(\"  --> Vertex Number {0} and ID {1}\".format(vertexNum, vertexID))\n",
    "\n",
    "                for key in keys:\n",
    "                    value   = vertex[key]\n",
    "\n",
    "                    result = None\n",
    "                    if isinstance(value, list):\n",
    "                        try:\n",
    "                            test = value[0][0]\n",
    "                            if test is None:\n",
    "                                result = 'N'\n",
    "                            else:\n",
    "                                if test == 1.0:\n",
    "                                    result = 'Y'\n",
    "                                else:\n",
    "                                    result = 'N'\n",
    "                        except:\n",
    "                            result = 'N'\n",
    "                    else:\n",
    "                        print(\"Input {0} is type {1}\".format(value, type(value)))\n",
    "\n",
    "                    self.setVertexFeature(vertexName, key, result)\n",
    "                    if verydebug is True:\n",
    "                        print(\"\\t: {0}, {1} == {2}\".format(key, value, result))\n",
    "                    \n",
    "        if verydebug:\n",
    "            raise ValueError(\"Stoppping after verydebug is True\")                    \n",
    "            \n",
    "\n",
    "    def fillInternalData(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Vertex Internal Data\")\n",
    "        verydebug=False\n",
    "\n",
    "        keys = [k for k,v in self.getVertexAttrs().items() if v == \"General\"]\n",
    "        for vertexName in self.getVertices():\n",
    "            vertex = self.getVertexByName(vertexName, 'attr')\n",
    "            if verydebug:\n",
    "                print(\"  --> Vertex Number {0} and ID {1}\".format(vertexNum, vertexID))\n",
    "\n",
    "            for key in keys:\n",
    "                value   = vertex[key]\n",
    "                feature = self.categories.getFeatures(key, value, debug)\n",
    "                if isinstance(feature, dict):\n",
    "                    feature = feature.get('Name')\n",
    "                self.setVertexFeature(vertexName, key, feature)\n",
    "                if verydebug is True:\n",
    "                    print(\"\\t: {0}, {1} == {2}\".format(key, value, feature))\n",
    "                    \n",
    "        if verydebug:\n",
    "            raise ValueError(\"Stoppping after verydebug is True\")                             \n",
    "            \n",
    "\n",
    "    def fillEdgeData(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Edge Data\")\n",
    "        verydebug=False\n",
    "\n",
    "        for edgeName in self.getEdges():\n",
    "            features = [self.getVertexByName(x, 'feat') for x in tuple(edgeName)]\n",
    "            for key,feat1 in features[0].items():\n",
    "                feat2 = features[1][key]\n",
    "                value = [str(feat1), str(feat2)]\n",
    "                self.setEdgeFeature(edgeName, key, value)\n",
    "                if verydebug is True:\n",
    "                    print(\"\\t: {0}, {1} == {2}\".format(edgeName, key, value))\n",
    "                    \n",
    "        if verydebug:\n",
    "            raise ValueError(\"Stoppping after verydebug is True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Creating a driver network with 88 vertices and 575 edges.\n",
      "Creating Network Attributes\n",
      "Updating Vertex Attributes\n",
      "Updating Vertices/Edges\n",
      "Ordering Edges by Weight\n",
      "Ordering Vertices by Centrality\n",
      "Flattening Vertices/Edges\n",
      "Collecting Edge Attributes\n",
      "Flattening Vertex Attributes\n",
      "Collecting Vertices/Edges\n",
      "Collecting Edge Attributes\n",
      "Collecting Vertex Attributes\n",
      "Creating Vertex Attributes DataFrame\n",
      "Filling Vertex Census Data\n",
      "dict_keys(['DayOfWeek', 'DrivingDistance', 'GeoDistanceRatio', 'N', 'First', 'Last', 'CoM', 'Geo', 'Radius', 'Cells', 'Quantiles', 'Geohashs', 'DwellTime', 'DailyVisits', 'OvernightStays', 'CENSUSCbsa', 'CENSUSCsa', 'CENSUSMetdiv', 'CENSUSPlace', 'CENSUSCousub', 'CENSUSCounty', 'CENSUSState', 'POIHEREAttraction', 'POIHEREAuto', 'POIHEREBuilding', 'POIHERECollege', 'POIHERECommercial', 'POIHERECycling', 'POIHEREEntertainment', 'POIHEREFastfood', 'POIHEREFuel', 'POIHEREGrocery', 'POIHEREIndustrial', 'POIHERELodging', 'POIHEREMedical', 'POIHEREMunicipal', 'POIHEREParking', 'POIHERERecreation', 'POIHERERestaurant', 'POIHERESchool', 'POIHERESport', 'POIHERETransit', 'OSMBeach', 'OSMCaveEntrance', 'OSMCliff', 'OSMGlacier', 'OSMPeak', 'OSMSpring', 'OSMTree', 'OSMVolcano', 'OSM4101', 'OSM4111', 'OSM4113', 'OSM4112', 'OSM4121', 'OSM4141', 'OSM4132', 'OSM4103', 'OSMCity', 'OSMCounty', 'OSMHamlet', 'OSMIsland', 'OSMLocality', 'OSMRegion', 'OSMSuburb', 'OSMTown', 'OSMVillage', 'OSM1003', 'OSM1004', 'OSM1050', 'OSM1001', 'OSM1002', 'OSM1041', 'OSM1010', 'OSMFarmPlace', 'OSM1020', 'OSM1030', 'OSMNationalCapital', 'OSMAllotments', 'OSMCemetery', 'OSMCommercial', 'OSMFarm', 'OSMForest', 'OSMGrass', 'OSMHeath', 'OSMIndustrial', 'OSMMeadow', 'OSMMilitary', 'OSMNatureReserve', 'OSMOrchard', 'OSMPark', 'OSMQuarry', 'OSMRecreationGround', 'OSMResidential', 'OSMRetail', 'OSMScrub', 'OSMVineyard', 'OSMCanal', 'OSMDock', 'OSMDrain', 'OSMGlacierWater', 'OSMReservoir', 'OSMRiver', 'OSMStream', 'OSMWater', 'OSMWetland', 'OSMFuel', 'OSMParking', 'OSMBuddhist', 'OSMChristian', 'OSMHindu', 'OSMJewish', 'OSMMuslim', 'OSMSikh', 'OSMTaoist', 'OSMBus', 'OSMFerry', 'OSMRail', 'OSMTaxi', 'OSMTram', 'OSMAttraction', 'OSMAuto', 'OSMBuilding', 'OSMCollege', 'OSMBusiness', 'OSMEntertainment', 'OSMFastfood', 'OSMGrocery', 'OSMManufacturing', 'OSMLodging', 'OSMMedical', 'OSMMunicipal', 'OSMPublic', 'OSMRecreation', 'OSMReligious', 'OSMRestaurant', 'OSMSchool', 'OSMSport', 'ROADSInterstate', 'ROADSUsrte', 'ROADSStaterte', 'ROADSHighway', 'ROADSMajorRd', 'ROADSRoad', 'RAILRail', 'TERMINALSAirport', 'TERMINALSAmtrak', 'POIASDWUniqueVisits', 'Interval', 'FractionalActive'])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-495945e02c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#dn.computeNetworkAttrs(debug=True, level=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillCensusData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillGeospatialData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillInternalData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1680eb89588a>\u001b[0m in \u001b[0;36mfillCensusData\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetVertexAttrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mcensusKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetVertexAttrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Census\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from edgeInfo import edgeInfo\n",
    "from vertexInfo import vertexInfo\n",
    "from networkCategories import categories\n",
    "\n",
    "\n",
    "dn = driverNetwork(trips)\n",
    "dn.create(debug=True)\n",
    "#dn.computeNetworkAttrs(debug=True, level=1)\n",
    "dn.fillCensusData(debug=True)\n",
    "dn.fillGeospatialData(debug=True)\n",
    "dn.fillInternalData(debug=True)\n",
    "dn.fillEdgeData(debug=True)\n",
    "g = dn.getNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn.vertexAttrsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = tmp[tmp['Geo1CensusCsaID'] == 'nan']\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(0, inplace=True)\n",
    "#df.replace('nan', None, inplace=True)\n",
    "#tmp = list(df['Geo1CensusCsaID']) + list(df['Geo0CensusCsaID'])\n",
    "#tmp\n",
    "#df[df == 'nan']\n",
    "tmp = df[df['Geo1CensusCsaID'] == 'nan']\n",
    "tmp[\"Geo1CensusCsaID\"] == 'nan'\n",
    "tmp.replace('nan', 0, inplace=True)\n",
    "tmp[\"Geo1CensusCsaID\"]\n",
    "#dn.getVertex(0, 'feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class networkFeatures():\n",
    "    def __init__(self, dn):\n",
    "        self.dn = dn\n",
    "        self.features = {}\n",
    "        \n",
    "        self.categories        = categories(debug)\n",
    "        self.getCategories     = self.categories.getCategories\n",
    "        self.getCategory       = self.categories.getCategory\n",
    "        self.getPermCategories = self.categories.getPermCategories\n",
    "        self.getPermCategory   = self.categories.getPermCategory  \n",
    "        self.getHomeRatioCategory = self.categories.getHomeRatioCategory\n",
    "        self.getIntervalCategory = self.categories.getIntervalCategory\n",
    "        \n",
    "        \n",
    "\n",
    "    #################################################################################################################\n",
    "    # Vertex/Edge Counts\n",
    "    #################################################################################################################\n",
    "    def fillVertexCounts(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Vertex Counts\")\n",
    "            \n",
    "        featureNames = None\n",
    "            \n",
    "        from collections import Counter\n",
    "        vertexCounts = {\"N\": {}, 3: {}, 10: {}, 25: {}}\n",
    "\n",
    "        for vertexNum,vertexName in enumerate(self.dn.getVertices()):\n",
    "            vertex = dn.getVertexByName(vertexName, 'feat')\n",
    "            if featureNames is None:\n",
    "                featureNames = list(vertex.keys())\n",
    "                for featureName in featureNames:\n",
    "                    featCats = self.getCategories(featureName)\n",
    "                    if featCats is not None:\n",
    "                        for cat in featCats:\n",
    "                            key = \"\".join([featureName,cat])\n",
    "                            for cutoff in [\"N\",3,10,25]:\n",
    "                                vertexCounts[cutoff][key]  = 0\n",
    "                    else:\n",
    "                        for cutoff in [\"N\",3,10,25]:\n",
    "                            vertexCounts[cutoff][featureName]  = 0\n",
    "                        \n",
    "            \n",
    "            for featureName in featureNames:                \n",
    "                value = vertex[featureName]\n",
    "                featCats = self.getCategories(featureName)\n",
    "                if featCats is not None and value in featCats:\n",
    "                    key = \"\".join([featureName,value])\n",
    "                    vertexCounts[\"N\"][key] += 1\n",
    "                    for cutoff in [3,10,25]:\n",
    "                        if vertexNum < cutoff:\n",
    "                            vertexCounts[cutoff][key] += 1\n",
    "                            \n",
    "                            \n",
    "        retval = {}\n",
    "        for cutoff,cutoffData in vertexCounts.items():\n",
    "            for key,value in cutoffData.items():\n",
    "                if retval.get(key) is None:\n",
    "                    retval[key] = {}\n",
    "                if isinstance(cutoff, int):\n",
    "                    retval[key][\"\".join([\"Top\", str(cutoff)])] = value\n",
    "                else:\n",
    "                    retval[key][cutoff] = value\n",
    "                                \n",
    "        self.features[\"Vertex_Counts\"] = retval\n",
    "        \n",
    "            \n",
    "\n",
    "    #################################################################################################################\n",
    "    # Vertex/Edge Properties\n",
    "    #################################################################################################################\n",
    "    def fillObjectProperties(self, objectData, debug=False):\n",
    "        try:\n",
    "            diffVtx0Vtx1  = float(objectData[0] - objectData[1])\n",
    "        except:\n",
    "            diffVtx0Vtx1  = None\n",
    "\n",
    "        try:\n",
    "            diffVtx1Vtx2  = float(objectData[1] - objectData[2])\n",
    "        except:\n",
    "            diffVtx1Vtx2  = None\n",
    "\n",
    "        try:\n",
    "            diffVtx0Vtx12 = float(objectData[0] - objectData[1] - objectData[2])\n",
    "        except:\n",
    "            diffVtx0Vtx12 = None\n",
    "\n",
    "        try:\n",
    "            qvals = list(objectData.quantile(q=[0.05,0.25,0.5,0.75,0.95]))\n",
    "        except:\n",
    "            qvals = [None, None, None, None, None]\n",
    "\n",
    "        retval = {\"Diff_First_Second\":  diffVtx0Vtx1,\n",
    "                  \"Diff_Second_Third\":  diffVtx1Vtx2,\n",
    "                  \"Diff_Top3\":         diffVtx0Vtx12,\n",
    "                  \"Very_Low_Quantile\":  qvals[0],\n",
    "                  \"Low_Quantile\":      qvals[1],\n",
    "                  \"Mid_Quantile\":      qvals[2],\n",
    "                  \"High_Quantile\":     qvals[3],\n",
    "                  \"Very_High_Quantile\": qvals[4]}\n",
    "        return retval\n",
    "        \n",
    "\n",
    "    def fillVertexProperties(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Vertex Properties\")\n",
    "\n",
    "        retval = {}\n",
    "        vertexAttrs = self.dn.nodeAttrs\n",
    "        for attribute in vertexAttrs.columns:\n",
    "            vertexData = getColData(vertexAttrs, colnames=attribute)            \n",
    "            retval[attribute] = self.fillObjectProperties(vertexData)\n",
    "\n",
    "        self.features[\"Vertex_Properties\"] = retval\n",
    "        \n",
    "\n",
    "    def fillEdgeProperties(self, debug=False):\n",
    "        if debug:\n",
    "            print(\"Filling Edge Properties\")\n",
    "\n",
    "        retval = {}\n",
    "        edgeAttrs = self.dn.edgeAttrs\n",
    "        for attribute in edgeAttrs.columns:\n",
    "            edgeData = getColData(edgeAttrs, colnames=attribute)\n",
    "            retval[attribute] = self.fillObjectProperties(edgeData)\n",
    "\n",
    "        self.features[\"Edge_Properties\"] = retval\n",
    "\n",
    "        \n",
    "        \n",
    "    #################################################################################################################\n",
    "    # Top Vertex/Edge Features\n",
    "    #################################################################################################################\n",
    "    def fillIndividualVertexFeatures(self, debug=False):\n",
    "        key = \"Vertex_Top5\"\n",
    "        retval = {}\n",
    "        \n",
    "        for vertexNum in range(5):\n",
    "            vertex = dn.getVertex(vertexNum, 'feat')\n",
    "            retval[\"{0}\".format(vertexNum)] = self.fillIndividualObjectFeatures(vertexNum, vertex, debug=debug)\n",
    "            \n",
    "        self.features[key] = retval\n",
    "        \n",
    "        \n",
    "    def fillIndividualEdgeFeatures(self, debug=False):\n",
    "        key = \"Edge_Top5\"\n",
    "        retval = {}\n",
    "        \n",
    "        for edgeNum in range(5):\n",
    "            edge = dn.getEdge(edgeNum, 'feat')\n",
    "            retval[\"{0}\".format(edgeNum)] = self.fillIndividualObjectFeatures(edgeNum, edge, debug=debug)\n",
    "            \n",
    "        self.features[key] = retval\n",
    "        \n",
    "        \n",
    "    def fillIndividualObjectFeatures(self, objectNum, objectData, debug=False):\n",
    "        retval = {}\n",
    "        retval['Rank'] = objectNum\n",
    "        for featureName, featureValue in objectData.items():\n",
    "            retval[featureName] = featureValue\n",
    "        return retval\n",
    "        \n",
    "        \n",
    "    def fillNetworkFeatures(self, debug=False):\n",
    "        key = \"Network\"\n",
    "        retval = {}\n",
    "        \n",
    "        netAttrs = self.dn.netAttrs\n",
    "        for featureName, featureValue in netAttrs.items():\n",
    "            retval[featureName] = featureValue\n",
    "            \n",
    "        self.features[key] = retval\n",
    "\n",
    "\n",
    "    def fillHomeFeatures(self, debug=False):\n",
    "        key = \"Home\"\n",
    "        retval = {}\n",
    "        \n",
    "        vertexName = str(dn.homeMetrics['Vtx'])\n",
    "        vertexData = dn.getVertexByName(vertexName, 'feat')\n",
    "        vertexNum  = dn.getVertexNum(vertexName)\n",
    "        retval[\"Rank\"] = vertexNum\n",
    "        ratio = dn.homeMetrics['Ratio']\n",
    "        ratio_significance = self.getHomeRatioCategory(ratio, debug)\n",
    "        retval[\"Ratio\"]    = ratio_significance\n",
    "        retval[\"Days\"]     = dn.homeMetrics['Days']\n",
    "        retval[\"Days\"], _  = self.getIntervalCategory(retval[\"Days\"], debug)\n",
    "        for featureName, featureValue in vertexData.items():\n",
    "            retval[featureName] = featureValue\n",
    "\n",
    "        self.features[key] = retval\n",
    "        \n",
    "                \n",
    "        \n",
    "    #################################################################################################################\n",
    "    # Feature Correlations\n",
    "    #################################################################################################################\n",
    "    def fillFeatureCorrelations(self, debug=False):\n",
    "        key = \"Vertex_Corr\"\n",
    "        retval = {}\n",
    "        \n",
    "        vertexAttrs = self.dn.nodeAttrs\n",
    "        for i,attribute1 in enumerate(vertexAttrs.columns):\n",
    "            vertexData1 = getColData(vertexAttrs, colnames=attribute1)\n",
    "            for j,attribute2 in enumerate(vertexAttrs.columns):\n",
    "                if j <= i:\n",
    "                    continue\n",
    "                    \n",
    "                vertexData2 = getColData(vertexAttrs, colnames=attribute2)               \n",
    "                try:\n",
    "                    corr = vertexData1.corr(vertexData2)\n",
    "                except:\n",
    "                    corr = None\n",
    "                retval[\"_\".join([attribute1, attribute2])] = corr\n",
    "\n",
    "        self.features[key] = retval\n",
    "        \n",
    "        key = \"Edge_Corr\"\n",
    "        retval = {}\n",
    "        \n",
    "        edgeAttrs = self.dn.edgeAttrs\n",
    "        for i,attribute1 in enumerate(edgeAttrs.columns):\n",
    "            edgeData1 = getColData(edgeAttrs, colnames=attribute1)\n",
    "            for j,attribute2 in enumerate(edgeAttrs.columns):\n",
    "                if j <= i:\n",
    "                    continue\n",
    "                    \n",
    "                edgeData2 = getColData(edgeAttrs, colnames=attribute2)               \n",
    "                try:\n",
    "                    corr = edgeData1.corr(edgeData2)\n",
    "                except:\n",
    "                    corr = None\n",
    "                retval[\"_\".join([attribute1, attribute2])] = corr\n",
    "\n",
    "        self.features[key] = retval\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #######################################################################################################################\n",
    "    #\n",
    "    # Create DataFrame\n",
    "    #\n",
    "    #######################################################################################################################\n",
    "    def fixType(self, value):\n",
    "        import numpy as np\n",
    "        if isinstance(value, tuple):\n",
    "            value = str(value)\n",
    "        elif isinstance(value, np.int64):\n",
    "            value = int(value)\n",
    "        elif isinstance(value, np.float64):\n",
    "            value = float(value)\n",
    "        elif isinstance(value, str):\n",
    "            value = str(value)\n",
    "        elif isinstance(value, float):\n",
    "            value = float(value)\n",
    "        elif isinstance(value, int):\n",
    "            value = int(value)\n",
    "        elif isinstance(value, type(None)):\n",
    "            value = None\n",
    "        else:\n",
    "            raise ValueError(\"Unknown Type: {0} --> {1}\".format(type(value), value))\n",
    "        return value\n",
    "                        \n",
    "    def getFeatureDataFrame(self, debug=False):\n",
    "        from pandas import DataFrame\n",
    "        from collections import Counter\n",
    "        features = {}\n",
    "        cntr = Counter()\n",
    "        for category, categorydata in self.features.items():\n",
    "            for feature, featuredata in categorydata.items():\n",
    "                if isinstance(featuredata, dict):\n",
    "                    for subfeature, subfeaturedata in featuredata.items():\n",
    "                        key = \"_\".join([category,feature,subfeature])\n",
    "                        key = \"\".join([s.title() for s in key.split(\"_\")])\n",
    "                        value = self.fixType(subfeaturedata)\n",
    "                        features[key] = value\n",
    "                else:\n",
    "                    key = \"_\".join([category,feature])\n",
    "                    key = \"\".join([s.title() for s in key.split(\"_\")])\n",
    "                    value = self.fixType(featuredata)\n",
    "                    features[key] = value\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Created Data Frame with {0} features\".format(len(features)))\n",
    "\n",
    "        if False:\n",
    "            features['Device'] = self.device\n",
    "            if self.expectedFeatures is not None:\n",
    "                if len(features) != self.expectedFeatures:\n",
    "                    print(\"\\nThere are only {0}/{1} features for {2}!!!\\n\".format(len(features), self.expectedFeatures, self.device))\n",
    "                    self.printFeatures()\n",
    "                    raise ValueError(\"\\nThere are only {0}/{1} features for {2}!!!\\n\".format(len(features), self.expectedFeatures, self.device))\n",
    "\n",
    "        df = DataFrame(features, index=[0])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = networkFeatures(dn)\n",
    "nf.fillEdgeProperties()\n",
    "nf.fillVertexCounts()\n",
    "nf.fillVertexProperties()\n",
    "nf.fillIndividualVertexFeatures()\n",
    "nf.fillIndividualEdgeFeatures()\n",
    "nf.fillNetworkFeatures()\n",
    "nf.fillHomeFeatures()\n",
    "nf.fillFeatureCorrelations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.getFeatureDataFrame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v,x for v,x in trips[\"vertexMetrics\"].items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn.getVertexByName(str(dn.homeMetrics['Vtx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn.homeMetrics\n",
    "dn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[1]['CoM'] for x in g.nodes(data=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runNetworkAlgorithms(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(a.keys()).intersection(set(b.keys()))\n",
    "dn.vertexAttrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx.reindex = list(g.edges())\n",
    "#df = DataFrame(x['Edges'])\n",
    "#df.columns.droplevel()\n",
    "#df.reindex = list(g.edges())\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeAlgos = []\n",
    "edgeAlgos = []\n",
    "netAlgos  = []\n",
    "noneAlgos = []\n",
    "for k,v in x.items():\n",
    "    if v is None:\n",
    "        noneAlgos.append(k)\n",
    "        continue\n",
    "    if isinstance(v, dict):\n",
    "        if len(v) == 20:\n",
    "            nodeAlgos.append(k)\n",
    "        elif len(v) == 186:\n",
    "            edgeAlgos.append(k)\n",
    "        else:\n",
    "            netAlgos.append(k)\n",
    "    else:\n",
    "        netAlgos.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodeAlgos\n",
    "#edgeAlgos\n",
    "import json\n",
    "json.dumps(edgeAlgos)\n",
    "#netAlgos\n",
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#algosToRun.append(algos.eulerian_circuit)\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algosToRun = []\n",
    "#algosToRun.append(algos.node_classification.harmonic_function)\n",
    "#algosToRun.append(algos.node_classification.local_and_global_consistency)\n",
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algosToRun = []\n",
    "#algosToRun.append(algos.sigma)\n",
    "#algosToRun.append(algos.omega)\n",
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sparse Matrix\n",
    "algosToRun = []\n",
    "algosToRun.append(linalg.attr_sparse_matrix)\n",
    "#algosToRun.append(convert_matrix.from_scipy_sparse_matrix)\n",
    "algosToRun.append(convert_matrix.to_pandas_adjacency)\n",
    "#runAlgos(algosToRun, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_matrix.to_pandas_edgelist(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(5)\n",
    "A = nx.nx_agraph.to_agraph(G)\n",
    "H = nx.nx_agraph.from_agraph(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.draw(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a graph.\n",
    "# Here I chose an ER graph.\n",
    "g = nx.erdos_renyi_graph(20, 0.3)\n",
    "\n",
    "# Get positions.\n",
    "# Here I use the spectral layout and add a little bit of noise.\n",
    "pos = nx.layout.spectral_layout(g)\n",
    "pos = nx.spring_layout(g, pos=pos, iterations=50)\n",
    "\n",
    "# Create position copies for shadows, and shift shadows\n",
    "pos_shadow = copy.deepcopy(pos)\n",
    "shift_amount = 0.006\n",
    "for idx in pos_shadow:\n",
    "    pos_shadow[idx][0] += shift_amount\n",
    "    pos_shadow[idx][1] -= shift_amount\n",
    "\n",
    "#~~~~~~~~~~~~\n",
    "# Draw graph\n",
    "#~~~~~~~~~~~~\n",
    "fig = plt.figure(frameon=False)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "\n",
    "nx.draw_networkx_nodes(g, pos_shadow, node_color='k', alpha=0.5)\n",
    "nx.draw_networkx_nodes(g, pos, node_color=\"#3182bd\", linewidths=1)\n",
    "nx.draw_networkx_edges(g, pos, width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "G = nx.Graph(day=\"Stackoverflow\")\n",
    "df_nodes = pd.read_csv('../input/stack_network_nodes.csv')\n",
    "df_edges = pd.read_csv('../input/stack_network_links.csv')\n",
    "\n",
    "for index, row in df_nodes.iterrows():\n",
    "    G.add_node(row['name'], group=row['group'], nodesize=row['nodesize'])\n",
    "    \n",
    "for index, row in df_edges.iterrows():\n",
    "    G.add_weighted_edges_from([(row['source'], row['target'], row['value'])])\n",
    "    \n",
    "color_map = {1:'#f09494', 2:'#eebcbc', 3:'#72bbd0', 4:'#91f0a1', 5:'#629fff', 6:'#bcc2f2',  \n",
    "             7:'#eebcbc', 8:'#f1f0c0', 9:'#d2ffe7', 10:'#caf3a6', 11:'#ffdf55', 12:'#ef77aa', \n",
    "             13:'#d6dcff', 14:'#d2f5f0'} \n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "options = {\n",
    "    'edge_color': '#FFDEA2',\n",
    "    'width': 1,\n",
    "    'with_labels': True,\n",
    "    'font_weight': 'regular',\n",
    "}\n",
    "colors = [color_map[G.node[node]['group']] for node in G]\n",
    "sizes = [G.node[node]['nodesize']*10 for node in G]\n",
    "\n",
    "\"\"\"\n",
    "Using the spring layout : \n",
    "- k controls the distance between the nodes and varies between 0 and 1\n",
    "- iterations is the number of times simulated annealing is run\n",
    "default k=0.1 and iterations=50\n",
    "\"\"\"\n",
    "nx.draw(G, node_color=colors, node_size=sizes, pos=nx.spring_layout(G, k=0.25, iterations=50), **options)\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor(\"#555555\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn.edgeDict[('0', '1')].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    minmaxWeight = [0.0, 2.5]\n",
    "    print(\"Number of Edges: {0}\".format(nEdges))\n",
    "    nRange=5\n",
    "    if nEdges > 100000:\n",
    "        minmaxWeight[1] = 2\n",
    "        nRange=6\n",
    "        weightSize = [power(x,11) for x in linspace(minmaxWeight[0], minmaxWeight[1], nRange)]\n",
    "    elif nEdges > 50000:\n",
    "        minmaxWeight[1] = 2\n",
    "        weightSize = [power(x,9) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    elif nEdges > 25000:\n",
    "        weightSize = [power(x,8) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    elif nEdges > 10000:\n",
    "        weightSize = [power(x,7) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    elif nEdges > 2000:\n",
    "        weightSize = [power(x,6) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    elif nEdges > 1000:\n",
    "        weightSize = [power(x,5) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    elif nEdges > 500:\n",
    "        weightSize = [power(x,4) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    elif nEdges > 100:\n",
    "        weightSize = [power(x,3) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    else:\n",
    "        weightSize = [power(x,2) for x in linspace(minmaxWeight[0], minmaxWeight[1], 5)]\n",
    "    scale = 2.5/amax(weightSize)\n",
    "    weightSize = [x*scale for x in weightSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,k2,v in g.edges(data=True):\n",
    "    print(v)\n",
    "    break\n",
    "#self.nodeDict = {u: d for (u,d) in self.g.nodes(data=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "x = Counter()\n",
    "x[3] += 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "tmp = Series([1, 3, 45,6 ,8, 34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tmp.quantile(q=[0.05,0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
